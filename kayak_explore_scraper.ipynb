{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, smtplib, os, datetime\n",
    "import pandas as pd\n",
    "from bs4 import *\n",
    "import urllib.request as ur\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Specify the beginning and end of the time frame of possible dates as YYYYMMDD\n",
    "timeframe_begin = 20200601\n",
    "timeframe_end = 20200830\n",
    "\n",
    "def scrape_kayak(start='', end='', airport = 'BER'):\n",
    "    \"\"\"\n",
    "    This function scrapes flight information from the kayak explore page.\n",
    "    \n",
    "    Parameters:\n",
    "    start, end, airport - integer representing earliest possible departure date\n",
    "    in YYYYMMDD format, integer representing latest return date, string with \n",
    "    three letter code for starting airport. When both are start and end are \n",
    "    left blank, results are returned from present date to one year in the \n",
    "    future.\n",
    "    \n",
    "    Returns:\n",
    "    df - a data frame containing all destination cities and corresponding \n",
    "    flight information returned by the scrape\n",
    "    \"\"\"\n",
    "\n",
    "    # Format the beginning and end dates to insert them into the URL\n",
    "    start = '&depart=' + str(start)\n",
    "    end = '&return=' + str(end)\n",
    "    \n",
    "    url = \"https://www.kayak.com/s/horizon/exploreapi/elasticbox?airport=\" + airport + \"&v=1\" + start + end + \\\n",
    "    \"&stopsFilterActive=false&duration=&budget=&topRightLat=68.58212830775821&topRightLon=180&bottomLeftLat=-6.168763628541718&bottomLeftLon=-180&zoomLevel=2\"\n",
    "    response = requests.post(url).json()\n",
    "\n",
    "    df = pd.DataFrame(columns=['City', 'Country', 'Price', 'Airline', 'Airport', 'Date', 'Link'])\n",
    "    \n",
    "    for i in range(len(response['destinations'])):\n",
    "        destination = response['destinations'][i]\n",
    "        row = list([destination['city']['name'], destination['country']['name'], \n",
    "                    destination['flightInfo']['price'], destination['airline'],\n",
    "                    destination['airport']['shortName'], pd.to_datetime(destination['departd']).date(),\n",
    "                    str('http://kayak.com'+destination['clickoutUrl'])])\n",
    "        df.loc[i] = row\n",
    "        \n",
    "    city_mins = df.groupby(['City']).idxmin().astype(int)\n",
    "    df = df.loc[city_mins['Price'].to_list()]\n",
    "    # There is a glitch where some flights are returned with unrealistically\n",
    "    # high prices, so we'll remove those entries.\n",
    "    df = df.where(df['Price']!=999999).dropna()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_wikipedia():\n",
    "    \"\"\"\n",
    "    This function scrapes and parses several wikipedia pages to map flight \n",
    "    destination cities to their respective continents. It then cleans the \n",
    "    resulting data frame.\n",
    "    \n",
    "    Returns:\n",
    "    df - a data frame containing all cities from the wiki data and the\n",
    "    continents where they are located\n",
    "    \"\"\"\n",
    "\n",
    "    urls = ['https://en.wikipedia.org/wiki/List_of_African_countries_by_area',\n",
    "           'https://en.wikipedia.org/wiki/List_of_North_American_countries_by_GDP_(nominal)_per_capita',\n",
    "           'https://en.wikipedia.org/wiki/List_of_South_American_countries_by_population',\n",
    "           'https://en.wikipedia.org/wiki/List_of_European_countries_by_area',\n",
    "           'https://en.wikipedia.org/wiki/List_of_Oceanian_countries_by_population',\n",
    "           'https://en.wikipedia.org/wiki/List_of_countries_in_Asia-Pacific_by_GDP_(nominal)',\n",
    "           'https://en.wikipedia.org/wiki/List_of_Middle_Eastern_countries_by_population']\n",
    "    \n",
    "    continents = ['Africa', 'North America', 'South America', 'Europe', \n",
    "                  'Oceania', 'Asia', 'Asia']    \n",
    "    all_continents, countries = [], []\n",
    "    df = pd.DataFrame(columns=['Country', 'Continent'])\n",
    "    \n",
    "    for i in range(len(urls)):\n",
    "        html = ur.urlopen(urls[i]).read()\n",
    "        soup = BeautifulSoup(html, 'html.parser') \n",
    "        table = soup.find_all('table')[0]  \n",
    "        rows = table.find_all('tr')\n",
    "        \n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            if len(columns) > 0:\n",
    "                country = columns[1].get_text().strip()\n",
    "                if country not in countries:\n",
    "                    countries.append(country)\n",
    "                    all_continents.append(continents[i])            \n",
    "    \n",
    "    # Remove all parentheses\n",
    "    countries = pd.Series(countries).replace(regex=True,\n",
    "                         to_replace=[r'\\d', r'\\([^)]*\\)', ''], value=r'')\n",
    "    # Remove brackets and asterisks\n",
    "    countries = countries.replace(regex=True,\n",
    "                                  to_replace=[r'\\[[^()]*\\]', r'[\\*]'],\n",
    "                                  value=r'')\n",
    "    df['Country'] = countries\n",
    "    df['Continent'] = pd.Series(all_continents)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(cities):\n",
    "    \"\"\"\n",
    "    This function finds the lowest priced flight to each continent, as well as \n",
    "    to specific regions we're interested in, in this case Japan and Hawaii.\n",
    "    \n",
    "    Parameters:\n",
    "    cities - a data frame with scraped kayak flight information with a \n",
    "    continent mapped to each city.\n",
    "    \n",
    "    Returns:\n",
    "    deals - a data frame containing flight information for the cheapest flight\n",
    "    to each destination of interest.\n",
    "    \"\"\"\n",
    "    \n",
    "    hi_airports = ['HNL', 'MKK', 'OGG', 'KOA', 'ITO']\n",
    "    hawaii = cities[cities['Airport'].str.match('LIH')]\n",
    "    \n",
    "    # Create a dataframe with all of the Hawaii flights\n",
    "    for airport in hi_airports:\n",
    "        hawaii = hawaii.append(cities[cities['Airport'].str.match(airport)])\n",
    "    \n",
    "    # Doing the same for Japan is a bit easier since we can just grep the\n",
    "    # country ccolumn\n",
    "    japan = cities[cities['Country'].str.match('Japan')]\n",
    "    jp_lowest = japan.loc[japan['Price'].idxmin()]\n",
    "    jp_lowest[7] = 'Japan*' # Differentiate the Japan flights from Asia flights\n",
    "    hi_lowest = hawaii.loc[hawaii['Price'].idxmin()]\n",
    "    hi_lowest[7] = 'Hawaii*'\n",
    "    lowest = cities.groupby(['Continent'])['Price'].idxmin()\n",
    "    deals = cities.iloc[lowest,:]\n",
    "    deals = deals.append(jp_lowest)\n",
    "    deals = deals.append(hi_lowest)\n",
    "    deals = deals.set_index('City')\n",
    "    \n",
    "    return deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_df(results, start, end):\n",
    "    \"\"\"\n",
    "    This function compares the results of the current scrape with previous\n",
    "    results to determine if an email update should be sent.\n",
    "    \n",
    "    Parameters: \n",
    "    results, start, end - dataframe with summarized scrape results, integer \n",
    "    representing earliest possible departure date in YYYYMMDD format, integer \n",
    "    representing latest return date\n",
    "    \n",
    "    Returns:\n",
    "    msgs, email - list of strings indicating continents for which good deals are \n",
    "    available, boolean indicating whether an email should be sent\n",
    "    \"\"\"\n",
    "    \n",
    "    filename = str(start) + '_to_' + str(end) + '_kayak_scrape.csv'\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['Date'])\n",
    "        \n",
    "    current_scrape = results['Price']\n",
    "    \n",
    "    # Append the current scrape as a row if it isn't a duplicate\n",
    "    if df.append(current_scrape).drop([\n",
    "            'Date'], axis=1).duplicated().any() == False:\n",
    "        df = df.append(current_scrape)\n",
    "        now = datetime.datetime.now()\n",
    "        df.iloc[-1,0] = now\n",
    "        df.index = range(len(df))\n",
    "\n",
    "    df.to_csv(filename, index=False)\n",
    "    msgs = ''\n",
    "    # Bool indicating if an email will be sent. Will be set to true if good \n",
    "    # deals are detected\n",
    "    email = False \n",
    "    # Percent of average flight price to a given destination; if a current price is \n",
    "    # under this threshold, an email alert will be generated\n",
    "    email_threshold = 0.85\n",
    "\n",
    "    for column in range(1,len(df.columns)):\n",
    "        col_mean = df.iloc[:,column].mean()\n",
    "        if col_mean * email_threshold > df.iloc[-1,column]:\n",
    "            name = df.columns[column]\n",
    "            msg = 'Flights to ' + name + ' right now are abnormally cheap.<br>'\n",
    "            msgs += msg\n",
    "            email = True\n",
    "            \n",
    "    return msgs, email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_email(flights):\n",
    "    \"\"\"\n",
    "    This function sends an email with the summarized flight data as a data \n",
    "    frame in html to the specified address. \n",
    "    \n",
    "    Parameters:\n",
    "    flights - a dataframe of the best deals on flights and the corresponding \n",
    "    details returned by our scrape.\n",
    "    \"\"\"\n",
    "    \n",
    "    password = input('Type your password:')\n",
    "    message = MIMEMultipart('alternative')\n",
    "    message.add_header('Content-Type','html')\n",
    "    sender = 'youremail@domain.com'\n",
    "    receiver = 'theiremail@domain.com'\n",
    "    message['Subject'] = \"Here is your latest Kayak scrape!\"\n",
    "    message['From'] = sender\n",
    "    message['To'] = receiver\n",
    "    html = \"<html><head></head><body><p>\" + msgs + \\\n",
    "    flights.to_html() + \". </p></body></html>\"\n",
    "    \n",
    "    part1 = MIMEText(html, 'html')\n",
    "    message.attach(part1)\n",
    "    mail = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    mail.ehlo()\n",
    "    mail.starttls()\n",
    "    mail.login('your_username', password)\n",
    "    mail.sendmail(sender, receiver.split(','), message.as_string())\n",
    "    mail.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scrape(flights, start, end):\n",
    "    \"\"\"\n",
    "    This function appends a column containing all of the current scraped prices\n",
    "    to a dataframe of saved flight price data.\n",
    "    \n",
    "    Parameters: \n",
    "    flights, start, end - dataframe with all scraped flight results, integer \n",
    "    representing earliest possible departure date in YYYYMMDD format, integer \n",
    "    representing latest return date\n",
    "    \n",
    "    Returns:\n",
    "    dataframe containing all previously scraped flight data plus the current scrape\n",
    "    \"\"\"\n",
    "    filename = str(start) + '_to_' + str(end) + '_all_flights.csv'\n",
    "    now = datetime.datetime.now()\n",
    "    current_prices = flights.set_index('City')['Price']\n",
    "    current_prices.name = now\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename, index_col=0)\n",
    "        df = df.merge(current_prices, how='outer', left_index=True, \n",
    "                      right_index=True)\n",
    "    else:\n",
    "        df = pd.DataFrame(current_prices)\n",
    "        df['Continent'] = flights_list.set_index('City')['Continent']\n",
    "        \n",
    "    df.to_csv(filename)\n",
    "    \n",
    "    return df.drop('Continent', axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_flights = scrape_kayak(timeframe_begin, timeframe_end)\n",
    "\n",
    "# If we've already run the scraper, there's no need to scrape wikipedia a\n",
    "# second time.\n",
    "if not os.path.isfile('continents.csv'):\n",
    "    all_continents = scrape_wikipedia()\n",
    "else:\n",
    "    all_continents = pd.read_csv('continents.csv', index_col=0)\n",
    "    \n",
    "flights_list = all_flights.merge(all_continents, how='left', on='Country')\n",
    "historical = save_scrape(timeframe_begin, timeframe_end, flights_list)\n",
    "results = summarize_results(flights_list)\n",
    "msgs, email = check_df(results, timeframe_begin, timeframe_end)\n",
    "\n",
    "if email:\n",
    "    send_email(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = ['Africa', 'North America', 'South America', \n",
    "              'Europe', 'Oceania', 'Asia']\n",
    "plot_num = 1\n",
    "\n",
    "for continent in continents:\n",
    "    plt.subplot(3,2,plot_num)\n",
    "    df = flights_list.where(flights_list['Continent']==continent).dropna()\n",
    "    plt.hist(df['Price'], bins=50, alpha=0.5, range=(0,3000))\n",
    "    title = plt.gca().set_title(continent)\n",
    "    plot_num += 1\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "dest_prices, labels = [], []\n",
    "\n",
    "# This lists cities from Hawaii and Japan to which flights are present in our\n",
    "# data frame.\n",
    "bp_cities = ['Honolulu', 'Kailua-Kona', 'Kahului', 'Lihue', 'Osaka', 'Nagoya', \n",
    "          'Tokyo', 'Sapporo', 'Okinawa']\n",
    "\n",
    "for city in bp_cities:\n",
    "        df = historical[historical.index.str.match(city)].T\n",
    "        if df.shape[1] > 0:\n",
    "            df = pd.Series(df[city]).tolist()\n",
    "            dest_prices.append(df)\n",
    "            labels.append(city)\n",
    "        \n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(dest_prices, labels=labels, whis=2)\n",
    "plt.ylabel('Price in USD')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
